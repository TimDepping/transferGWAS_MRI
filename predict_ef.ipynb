{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Resnet + Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define head structure\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "class FlattenLayer(Lambda):\n",
    "    def __init__(self):\n",
    "        super().__init__(func=lambda x: x.view(len(x), -1))\n",
    "\n",
    "head = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)), FlattenLayer(), nn.Linear(2048, 1))\n",
    "\n",
    "## Create hook for feature maps of resnet\n",
    "feature_maps = []\n",
    "def hook_fn(module, input, output):\n",
    "    # Store the output of the module in a list\n",
    "    feature_maps.append(output)\n",
    "\n",
    "## Load model \n",
    "model_path = '/dhc/groups/mpws2022cl1/models/testModel_head.pt'\n",
    "m_func = models.resnet50\n",
    "model = m_func(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(\n",
    "                50, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "            )\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['resnet_state_dict'])\n",
    "head.load_state_dict(checkpoint['head_state_dict'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform each img of multi tensor\n",
    "\n",
    "def percentile_scaling_array(\n",
    "        array, lower_percentile=0, upper_percentile=98, min_val=0, max_val=1\n",
    "    ):\n",
    "        lower_bound = np.percentile(array, lower_percentile)\n",
    "        upper_bound = np.percentile(array, upper_percentile)\n",
    "        array = (array - lower_bound) / (upper_bound - lower_bound)\n",
    "        array = array * (max_val - min_val) + min_val\n",
    "        tensor = transforms.ToTensor()(array).float()\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_images = '/dhc/groups/mpws2022cl1/tensor/3000_GRAY/'\n",
    "df_images = pd.read_csv('/dhc/groups/mpws2022cl1/tensor/3000_GRAY.csv', header=0)\n",
    "df_labels = pd.read_csv('/dhc/groups/mpws2022cl1/input/ejectionFraction_normalized_multiChannel_38591.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns to df_images\n",
    "df_images = df_images.assign(label=\"\", prediction=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict EF for each entry in dir_images and print to dataframe 'df_images'\n",
    "### Also print the label, if existing, to the dataframe 'df_images'\n",
    "\n",
    "for index, row in df_images.iterrows():\n",
    "    # Open the file with the current path\n",
    "    file_path = os.path.join(dir_images, row['path'])\n",
    "    mcTensor = torch.load(file_path)\n",
    "\n",
    "    # ToTensor requires a numpy.ndarray (H x W x C)\n",
    "    ## 1) transform mcTensor to npArrayList (50x 1x1x224x224)\n",
    "    npArrays = mcTensor.numpy()\n",
    "    npArrayList = np.split(npArrays, 50, axis=0)\n",
    "    ## 2) remove dimensions of size 1 infront of the array 1,1,224,244 -> 224,244\n",
    "    npArrayList = np.squeeze(npArrayList)\n",
    "    ## 3) add dimentions of size 1 at the end of the array 224,244 -> 224,244,1\n",
    "    npArrayList = [array[:, :, np.newaxis] for array in npArrayList]\n",
    "    ## 4) scale tensor list + toTensor\n",
    "    scaledTensorList = [\n",
    "        percentile_scaling_array(array, 0, 98, 0, 1) for array in npArrayList\n",
    "    ]\n",
    "    ## 5) Get rid of the first dimension: [1,224,224] -> [224,224]\n",
    "    squeezed_tensors = [tensor.squeeze(0) for tensor in scaledTensorList]\n",
    "    ## 6) Stack all the transformed images back together to a create a 50 channel tensor\n",
    "    stacked_tensor = torch.stack(squeezed_tensors, dim=0)\n",
    "\n",
    "    ## Add batch dimension for resnet\n",
    "    input_tensor = stacked_tensor.unsqueeze(0) \n",
    "    input_tensor.shape\n",
    "\n",
    "    # Get the layer 4 module and register the hook\n",
    "    layer4 = model.layer4\n",
    "    feature_maps = []\n",
    "    layer4.register_forward_hook(hook_fn)\n",
    "\n",
    "    # Pass the input tensor through the model\n",
    "    model.eval()\n",
    "    head.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    layer4_feature_maps = feature_maps[0]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = head(layer4_feature_maps)\n",
    "\n",
    "    ef_predicted = output.item()\n",
    "\n",
    "    df_images.loc[index, 'prediction'] = ef_predicted\n",
    "\n",
    "    # add the label to that row\n",
    "    entry = row['path'][:-3]\n",
    "    if entry in df_labels[\"image\"].values:\n",
    "        row_index = df_labels.index[df_labels[\"image\"] == entry].tolist()[0]\n",
    "        ef_value = df_labels.loc[row_index, \"Ejection Fraction\"]\n",
    "        df_images.loc[index, 'label'] = ef_value\n",
    "    \n",
    "    print(df_images.loc[index])\n",
    "\n",
    "df_images.to_csv(\"predict_ef.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transfer_gwas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc910ad0ce2a7603f15909527666fa83ce4a8e28f042ea6b6e566ba6f7a130b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
